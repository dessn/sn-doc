

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>dessn.framework.models package &mdash; DES Supernova BHM 0.0.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/theme_override.css" type="text/css" />
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html" class="icon icon-home"> DES Supernova BHM
          

          
          </a>

          
            
            
              <div class="version">
                0.0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="investigations_sep.html">Investigations</a></li>
<li class="toctree-l1"><a class="reference internal" href="implementations_sep.html">Implementations</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">DES Supernova BHM</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>dessn.framework.models package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/dessn.framework.models.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-dessn.framework.models">
<span id="dessn-framework-models-package"></span><h1>dessn.framework.models package<a class="headerlink" href="#module-dessn.framework.models" title="Permalink to this headline">¶</a></h1>
<p>My attempt at a proper STAN model.</p>
<div class="section" id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<p><strong>Cosmological parameters</strong>:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\Omega_m\)</span>: matter density</li>
<li><span class="math">\(w\)</span>: dark energy equation of state</li>
<li><span class="math">\(\alpha\)</span>: Phillips correction for stretch</li>
<li><span class="math">\(\beta\)</span>: Tripp correction for colour</li>
</ul>
</div></blockquote>
<p><strong>Population parameters</strong>:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\langle M_B \rangle\)</span>: mean absolute magnitude of supernova</li>
<li><span class="math">\(\sigma_{M_B}\)</span>: standard deviation of absolute magnitudes</li>
<li><span class="math">\(\langle c_i \rangle\)</span>: mean colour, as a function of redshift</li>
<li><span class="math">\(\sigma_c\)</span>: standard deviation of  colour</li>
<li><span class="math">\(\langle x_{i1} \rangle\)</span>: mean scale, as a function of redshift</li>
<li><span class="math">\(\sigma_{x_1}\)</span>: standard deviation of scale</li>
<li><span class="math">\(\rho\)</span>: correlation (matrix) between absolute magnitude, colour and stretch</li>
</ul>
</div></blockquote>
<p><strong>Marginalised parameters</strong>:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(\delta(0)\)</span> and <span class="math">\(\delta(\infty)\)</span>: The magnitude-mass relationship</li>
<li><span class="math">\(\delta \mathcal{Z}_b\)</span>: Zeropoint uncertainty for each of the <em>g,r,i,z</em> bands.</li>
</ul>
</div></blockquote>
<p><strong>Per supernova parameters</strong>:</p>
<blockquote>
<div><ul class="simple">
<li><span class="math">\(m_B\)</span>: the true (latent) apparent magnitude</li>
<li><span class="math">\(x_1\)</span>: the true (latent) stretch</li>
<li><span class="math">\(c\)</span>: the true (latent) colour</li>
<li><span class="math">\(z\)</span>: the true redshift of the supernova</li>
<li><span class="math">\(m\)</span>: the true mass of the host galaxy</li>
</ul>
</div></blockquote>
</div>
<hr class="docutils" />
<div class="section" id="model-overview">
<h2>Model Overview<a class="headerlink" href="#model-overview" title="Permalink to this headline">¶</a></h2>
<p>We wish to model our posterior, given our observations, our model <span class="math">\(\theta\)</span>, and
selection effects <span class="math">\(S\)</span>.
Our specific observations <span class="math">\(D\)</span> are the light curves themselves,
the summary statistics that result from them <span class="math">\(\lbrace \hat{m_B}, \hat{c}, \hat{x_1} \rbrace\)</span>,
the covariance for the summary statistics <span class="math">\(\hat{C}\)</span>, the redshifts of the
object <span class="math">\(\hat{z}\)</span> and a normalised mass estimate <span class="math">\(\hat{m}\)</span>. We thus signify
observed variables with the hat operator. In this work we will be modelling
<span class="math">\(\lbrace \hat{m_B}, \hat{c}, \hat{x_1} \rbrace\)</span> as having true underlying
values, however assume that  <span class="math">\(\hat{z}\)</span> and <span class="math">\(\hat{m}\)</span> are
known <span class="math">\((\hat{z} = z,\ \hat{m}=m)\)</span>.</p>
<p>For simplicity, we adopt the commonly used notation that <span class="math">\(\eta\equiv \lbrace \hat{m_B}, \hat{c}, \hat{x_1} \rbrace\)</span>.</p>
<div class="math">
\[\begin{split}P(\theta|D) &amp;\propto \mathcal{L}(D|\theta, S) P(\theta) \\\end{split}\]</div>
<p>with</p>
<div class="math">
\[\begin{split}\mathcal{L}(D|\theta, S) &amp;= \frac{P(S | D, \theta) P(D|\theta)}{\int P(S|R, \theta) P(R|\theta) \ dR}, \\\end{split}\]</div>
<p>where <span class="math">\(R\)</span> represents all possible data. To simplify notation in the future
I define <span class="math">\(w \equiv \int P(S|R, \theta) P(R|\theta) \ dR\)</span>.</p>
</div>
<hr class="docutils" />
<div class="section" id="stan-model">
<h2>STAN Model<a class="headerlink" href="#stan-model" title="Permalink to this headline">¶</a></h2>
<p>Let us examine only the numerator for the time being. The numerator is the model
which ends up implemented in STAN, whilst the denominator can be implemented
differently. For simplicity, let us denote the population parameters
<span class="math">\(\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle, \sigma_{M_B}, \sigma_{x_1}, \sigma_c, \rho \rbrace\)</span>
shown under the Population header as <span class="math">\(\gamma\)</span>.</p>
<p>Furthermore, in the interests of simplicity, let us examine only a single supernova for the time being. 
Let us denote the unnormalised likelihood for a single
supernova as <span class="math">\(P (D_i|\theta)\)</span>.</p>
<div class="math">
\[\begin{split}P (D_i|\theta) P(\theta) &amp;= P(\hat{m_B}, \hat{x_1}, \hat{c}, \hat{z}, \hat{m} |
\Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m)
P(\Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m) \\\end{split}\]</div>
<p>Now, let us quickly deal with the priors so I don&#8217;t have to type them out again and again.
We will treat <span class="math">\(\sigma_{M_B},\ \sigma_{x_1},\, \sigma_c\)</span>
with Cauchy priors, <span class="math">\(\rho\)</span> with an LKJ prior, <span class="math">\(\delta \mathcal{Z}_b\)</span> is constrained by
zero point uncertainty from photometry (currently just set to 0.01 mag normal uncertainty)
and other parameters with flat priors. The prior
distributions on redshift and host mass do not matter in this likelihood (without bias corrections),
as we assume redshift and mass are precisely known.
So now we can focus on the likelihood, and introduce latent variables <span class="math">\(\eta\)</span> to represent the true values
from which the observations are drawn from.</p>
<div class="math">
\[\begin{split}P (D_i|\theta) &amp;= \iiint d\eta \  P(\hat{\eta}, \eta |  z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b )  \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}P (D_i|\theta) &amp;= P(\hat{m_B}, \hat{x_1}, \hat{c}, \hat{z}, \hat{m} |
\Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m) \\[10pt]
&amp;= \int dm_B \int dx_1 \int dc \  P(\hat{m_B}, \hat{x_1}, \hat{c}, \hat{z}, \hat{m}, m_B, x_1, c | \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m) \\[10pt]
&amp;= \iiint d\eta \  P(\hat{\eta}, \hat{z}, \hat{m}, \eta | \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m) \\[10pt]
&amp;= \iiint d\eta \  \delta(\hat{z} - z) \delta(\hat{m}-m) P(\hat{\eta}, z, m, \eta | \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b, z, m) \\[10pt]
&amp;= \iiint d\eta \  P(\hat{\eta}, \eta |  z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b )  \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]\end{split}\]</div>
</div></blockquote>
</div>
<p>Where I have used the fact that we assume mass and redshift are precisely known
(<span class="math">\(\hat{z}=z\)</span> and <span class="math">\(\hat{m}=m\)</span>), and therefore do not need to be modelled with latent parameters. With precise
measurements, we do not need to consider the underlying redshift and mass distributions
<span class="math">\(P(z|\theta)\)</span> and <span class="math">\(P(m|\theta)\)</span> in this part of our model, as they will simply
modify the constant of proportionality, and thus I do not write them out.</p>
<p>We take zeropoint uncertainty into account by computing <span class="math">\(\frac{\partial\hat{\eta}}{\partial\mathcal{Z}_b}\)</span> for each supernova
light curve. We thus model what would be the observed values <span class="math">\(\hat{\eta}_{\rm True} = \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}_b}\)</span>,
and then assume that true observed summary statistics <span class="math">\(\hat{\eta}_{\rm True}\)</span> are normally
distributed around the true values <span class="math">\(\eta\)</span>, we can separate them out.</p>
<div class="math">
\[\begin{split}P (D_i|\theta) &amp;= \iiint d\eta \  \mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}_b} |\eta, C \right) P(\eta| z, m, \Omega_m, w, \alpha, \beta, \gamma)  \delta(\hat{z} - z) \delta(\hat{m}-m)  \\\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}P (D_i|\theta) &amp;= \iiint d\eta \  P(\hat{\eta} | \eta, z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b ) P(\eta| z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta \mathcal{Z}_b ) \delta(\hat{z} - z) \delta(\hat{m}-m)  \\[10pt]
&amp;= \iiint d\eta \  P(\hat{\eta} | \eta, \delta \mathcal{Z}_b) P(\eta | z, m, \Omega_m, w, \alpha, \beta, \gamma)  \delta(\hat{z} - z) \delta(\hat{m}-m)  \\[10pt]
&amp;= \iiint d\eta \  \mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}_b} |\eta, C \right) P(\eta| z, m, \Omega_m, w, \alpha, \beta, \gamma)  \delta(\hat{z} - z) \delta(\hat{m}-m)  \\\end{split}\]</div>
</div></blockquote>
</div>
<p>Now, in order to calculate <span class="math">\(P(\eta| \Omega_m, w, \alpha, \beta, \gamma, z, m, \delta\mathcal{Z}_b)\)</span>,
we need to transform from <span class="math">\(m_B\)</span> to <span class="math">\(M_B\)</span>. We transform using the following relationship:</p>
<div class="math">
\[M_B = m_B - \mu + \alpha x_1 - \beta c + k(z) m\]</div>
<p>where we define <span class="math">\(\mu\)</span> as</p>
<div class="math">
\[\begin{split}\mu &amp;= 5 \log_{10} \left[ \frac{(1 + z)c}{H_0 \times 10{\rm pc}} \int_0^z \left(
\Omega_m (1 + z)^3 + (1 - \Omega_m)(1+z)^{3(1+w)} \right) \right] \\\end{split}\]</div>
<p>and <span class="math">\(k(z)\)</span> as</p>
<div class="math">
\[\begin{split}k(z) &amp;= \delta(0) \left[ \frac{1.9\left( 1 - \frac{\delta(\infty)}{\delta(0)}
\right)}{0.9 + 10^{0.95z}} + \frac{\delta(\infty)}{\delta(0)} \right] \\\end{split}\]</div>
<p>We note that <span class="math">\(\mu\)</span> is a function of <span class="math">\(\hat{z},\Omega_m,w\)</span>, however we will simply denote it
<span class="math">\(\mu\)</span> to keep the notation from spreading over too many lines.</p>
<p>From the above,  <span class="math">\(M_B\)</span> is a function of <span class="math">\(\Omega_m, w, \alpha, \beta, x_1, c, z, m\)</span>. Or, more probabilistically,</p>
<div class="math">
\[P(M_B, m_B) = \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right).\]</div>
<p>We can thus introduce a latent variable <span class="math">\(M_B\)</span> and immediately remove the <span class="math">\(m_B\)</span> integral via the delta function.</p>
<div class="math">
\[\begin{split}P (D_i|\theta) &amp;= \iiint d\eta  \int dM_B \  \mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}_b} | \eta, C \right) P(\eta, M_B | z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta\mathcal{Z}_b) \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]\end{split}\]</div>
<p>where</p>
<div class="math">
\[\begin{split}P(\eta, M_B| \theta) &amp;= \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) \mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}P(\eta, M_B| \theta) &amp;= P(m_B | M_B, x_1, c, z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta\mathcal{Z}_b ) P (M_B, x_1, c, | z, m, \Omega_m, w, \alpha, \beta, \gamma, \delta\mathcal{Z}_b )\delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]
&amp;= \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) P (M_B, x_1, c | z, m,\Omega_m, w, \alpha, \beta, \gamma, \delta\mathcal{Z}_b ) \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]
&amp;= \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) P (M_B, x_1, c, | \gamma) \delta(\hat{z} - z) \delta(\hat{m}-m)\\[10pt]
&amp;= \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) \mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) \delta(\hat{z} - z) \delta(\hat{m}-m) \\[10pt]\end{split}\]</div>
</div></blockquote>
</div>
<p>with</p>
<div class="math">
\[\begin{split}V &amp;= \begin{pmatrix}
\sigma_{M_B}^2                        &amp; \rho_{12} \sigma_{M_B} \sigma_{x_1}         &amp; \rho_{13} \sigma_{M_B} \sigma_{c}  \\
\rho_{21} \sigma_{M_B} \sigma_{x_1}           &amp; \sigma_{x_1}^2                    &amp; \rho_{23} \sigma_{x_1} \sigma_{c}  \\
\rho_{31} \sigma_{M_B} \sigma_{c}          &amp; \rho_{32} \sigma_{x_1} \sigma_{c}       &amp; \sigma_{c}^2  \\
\end{pmatrix}\end{split}\]</div>
<p>giving the population covariance.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In this implementation there is no skewness in the colour distribution.
As we do not require normalised probabilities, we can simply add in correcting
factors that can emulate skewness. This has been done in the <code class="docutils literal"><span class="pre">simple_skew</span></code> model, where we
add in a CDF probability for the colour to turn our normal into a skew normal.</p>
</div>
<p>Putting this back together, we now have a simple hierarchical multi-normal model.
Adding in the priors, and taking into account that we observe multiple supernova, we have
that a final numerator of:</p>
<div class="math">
\[\begin{split}P(D_i|\theta) P(\theta) &amp;\propto
\rm{Cauchy}(\sigma_{M_B}|0,2.5)
\rm{Cauchy}(\sigma_{x_1}|0,2.5)
\rm{Cauchy}(\sigma_{c}|0,2.5)
\rm{LKJ}(\rho|4) \\
&amp;\quad  \iiint d\eta_i \int M_{Bi}\
\mathcal{N}\left( \hat{\eta_i} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta_i}}{\partial\mathcal{Z}_b} | \eta_i, C_i \right)
\delta\left(M_{Bi} - \left[ m_{Bi} - \mu_i + \alpha x_{1i} - \beta c_i + k(z_i) m_i\right]\right) \\
&amp;\quad\quad\quad \mathcal{N}\left( \lbrace M_{Bi}, x_{1i}, c_i \rbrace |
\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) \delta(\hat{z_i} - z_i) \delta(\hat{m_i}-m_i)\end{split}\]</div>
</div>
<hr class="docutils" />
<div class="section" id="selection-effects">
<h2>Selection Effects<a class="headerlink" href="#selection-effects" title="Permalink to this headline">¶</a></h2>
<p>Now, the easy part of the model is done, we need to move on to the real issue - our data is biased.
As the bias correction is not data dependent, but model parameter dependent (cosmology dependent),
the correction for each data point is identical, such that the correction for each individual supernova
is identical. I also note that, unlike the previous section, here we have to care about the
redshift and mass distributions, and so I will write them out.</p>
<p>We assume, for any given supernova, the selection effect can be determined as a function of apparent magnitude,
colour, stretch, redshift and mass. We might expect that the zero points have an effect
on selection efficiency, however this is because we normally consider zero points and
photon counts hand in hand. As we have a fixed experiment (fixed photon counts and statistics)
with different zero points, the selection efficiency is actually independent from zero points. Thus, we can
compute the bias correction as</p>
<div class="math">
\[\begin{split}w &amp;= \idotsint d\hat{\eta} \, d\eta \, dz\, dm\, dM_B\
\mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}} | \eta, C \right)\   P(S|m_B, x_1, c, z, m) \\
&amp;\quad\quad\quad  \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right)\
\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace |
\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) P(z|\theta) \\\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}w &amp;= \iiint d\hat{\eta} \iiint d\eta \int dM_B\  \int d\hat{z} \int \hat{m} \int dz \int dm \,
P(\hat{\eta},\eta, \hat{z},z, \hat{m},m, M_B|\theta) P(S|m_B, x_1, c, z, m)  \\[10pt]
&amp;= \idotsint d\hat{\eta} \, d\eta \, d\hat{z} \, dz\, d\hat{m}\, dm\, dM_B\
\mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}} | \eta, C \right)\   P(S|m_B, x_1, c, z, m)  \\
&amp;\quad\quad\quad  \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right)\
\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace |
\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)\delta(\hat{z} - z) \delta(\hat{m}-m) P(z|\theta) \\[10pt]
&amp;= \idotsint d\hat{\eta} \, d\eta \, dz\, dm\, dM_B\
\mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}} | \eta, C \right)\   P(S|m_B, x_1, c, z, m) \\
&amp;\quad\quad\quad  \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right)\
\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace |
\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) P(z|\theta)  \\\end{split}\]</div>
</div></blockquote>
</div>
<p>Again that we assume redshift and mass are perfectly known, so the relationship between
actual (latent) redshift and mass and the observed quantity is a delta function, hence why
they only appear once in the equation above. The important assumption
is that the detection efficiency is to good approximation
captured by the apparent magnitude, colour, stretch, mass and redshift of the supernova.</p>
<p>As we integrate over all possible realisations, we have that over all space</p>
<div class="math">
\[\begin{split}\iiint d\hat{\eta} \, P(\hat{\eta} | \eta, \delta\mathcal{Z}_b) =
\iiint_{-\infty}^{\infty} d\hat{\eta}\,
\mathcal{N}\left( \hat{\eta} + \delta\mathcal{Z}_b \frac{\partial\hat{\eta}}{\partial\mathcal{Z}} | \eta, C \right) = 1 \\\end{split}\]</div>
<p>and as such we can remove it from the integral. As is expected, the final weight looks exactly like our likelihood,
except with some extra integral signs that marginalise over all possible experimental realisations:</p>
<div class="math">
\[\begin{split}w &amp;= \idotsint d\eta\, dz \, dm \, dM_B\
P(S|m_B, x_1, c, z, m)  \delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) P(M_B, x_1, c | \gamma) P(z|\theta) \\\end{split}\]</div>
<p>Addressing each component individually:</p>
<div class="math">
\[\begin{split}P(M_B, x_1, c|\gamma) &amp;= \mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right) \\
P(S|m_B, x_1, c, z, m)  &amp;= \text{Probability of selection given actual underlying supernova values} \\
\delta\left(M_B - \left[ m_B - \mu + \alpha x_1 - \beta c + k(z) m\right]\right) &amp;= \text{Transformation function} \\
P(z|\theta)   &amp;= \text{Redshift distribution of supernova} \\\end{split}\]</div>
<p>Finally, we note that, having <span class="math">\(N\)</span> supernova instead of one, we need only to normalise the likelihood
for each new point in parameter space, but not at each individual data point (because the normalisation
is independent of the data point). Thus our final posterior takes the following form, where I explicitly take into
account the number of supernova we have:</p>
<div class="math">
\[\begin{split}P(\theta|D) &amp;\propto \frac{P(\theta)}{w^N} \idotsint d\vec{m_B}\, d\vec{x_1}\, \, d\vec{c}\, d\vec{M_B} \prod_{i=1}^N P(D_i|\theta) \\\end{split}\]</div>
<div class="green admonition note">
<p class="first admonition-title">Note</p>
<p><strong>Technical aside</strong>: Calculating :math:<a href="#id1"><span class="problematic" id="id2">`</span></a>P(S|m_B, x_1, c, z, m) `
is not an analytic task. It has complications not just in the distance modulus being the
result of an integral, but also that the colour and stretch correction factors make
extra use of supernova specific values. The way to efficiently determine the efficiency
is given as follows:</p>
<blockquote>
<div><ol class="arabic simple">
<li>Initially run a large DES-like simulation, recording all generated SN parameters and whether they pass the cuts.</li>
<li>Using input cosmology to translate <span class="math">\(m_B, x_1, c\)</span> distribution to a <span class="math">\(M_B, x_1, c\)</span> distribution.</li>
<li>Perform Monte-Carlo integration using the distribution.</li>
</ol>
</div></blockquote>
<p>This gives our correction <span class="math">\(w\)</span> as</p>
<div class="math">
\[\begin{split}w \propto \left[\sum_{\rm passed} \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace |
\lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}
\left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\, (P(z|\theta) dz)\, dm  \right]^N \\\end{split}\]</div>
<div class="toggle note math last admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<p>To go into the math, our Monte Carlo integration sample
of simulated supernova is drawn from the multivariate normal distribution <span class="math">\(\mathcal{N}_{\rm sim}\)</span>.</p>
<div class="math">
\[\begin{split}w^N &amp;= \left[ \frac{1}{N_{\rm sim}} \sum  P(S|m_B, x_1, c, z,m)  \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}     \left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\,(P(z|\theta) dz)\, dm  \right]^N \\
&amp;= \left[ \frac{1}{N_{\rm sim}} \sum_{\rm passed} \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}     \left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\, (P(z|\theta) dz)\, dm  \right]^N \\
&amp;=  \frac{1}{N_{\rm sim}^N} \left[\sum_{\rm passed} \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}     \left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\, (P(z|\theta) dz)\, dm  \right]^N\end{split}\]</div>
<p>As the weights do not have to be normalised, we can discard the constant factor out front. We also note that
determining whether a simulated supernova has passed the cut now means converting light curve counts to flux
and checking that the new fluxes pass signal-to-noise cuts.</p>
<div class="math">
\[\begin{split}w^N &amp;\propto  \left[\sum_{\rm passed} \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}     \left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\, (P(z|\theta) dz)\, dm  \right]^N \\
\log\left(w^N\right) - {\rm const} &amp;=  N \log\left[\sum_{\rm passed} \frac{\mathcal{N}\left( \lbrace M_B, x_1, c \rbrace | \lbrace \langle M_B \rangle, \langle x_1 \rangle, \langle c \rangle \rbrace, V \right)}{\mathcal{N}_{\rm sim}}     \left( \mathcal{N}_{\rm sim} dm_B\,d x_1\, d_c \right)\, (P(z|\theta) dz)\, dm  \right]\end{split}\]</div>
<p class="last">Given a set of points to use in the integration, we can see that subtracting the above
term from our log-likelihood provides an implementation of our bias correction.</p>
</div>
</div>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">A primary concern with selection effects is that they grow exponentially worse with
more data. To intuitively understand this, if you have an increased number of (biased)
data points, the posterior maximum becomes better constrained and you need an increased
re-weighting (bias correction) to shift the posterior maximum to the correct location. Because
of this, we will need to implement an approximate bias correction in Stan.</p>
</div>
<p>To recap, we have a full bias correction that can be computed using Monte-Carlo integration. However,
Monte-Carlo integration cannot be put inside the Stan framework, and having no bias correction
at all in the Stan framework means that our sampling efficiency drops to close to zero, which makes
it very difficult to adequately sample the posterior adequately. As such, we need an approximate
bias correction which <em>can</em> go inside Stan to improve our efficiency.</p>
<p>We can do this by looking at the selection efficiency simply as
a function of apparent magnitude for the supernova. There are two possibilities that we can do. The first
is to approximate the selection efficiency as a normal CDF, as was done in Rubin (2005). However, when
simulating the DES data, low spectroscopic efficiency at brighter magnitudes makes a CDF an inappropriate
choice. Instead, the most general analytic form we can prescribe the approximate correction
would be using a skew normal, as (depending on the value of the skew parameter <span class="math">\(\alpha\)</span>) we
can smoothly transition from a normal CDF to a normal PDF. Thus the approximate bias function
is described by</p>
<div class="math">
\[\begin{split}w_{\rm approx} &amp;= \int dz \left[ \int dm_B \,  S(m_B) P(m_B|z,\theta) \right] P(z|\theta) \\[10pt]\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}w_{\rm approx} &amp;= \int d\hat{z} \int d\hat{m_B} \, P(\hat{z},\hat{m_B}|\theta) S(m_B) \\[10pt]
&amp;= \int d\hat{z} \int d\hat{m_B} \int dz \int dm_B \, P(\hat{z},\hat{m_B},z,m_B|\theta)  S(m_B) \\[10pt]
&amp;= \int d\hat{z} \int d\hat{m_B} \int dz \int dm_B \, P(\hat{z}|z) P(\hat{m_B}|m_B) P(m_B|z,\theta) P(z|\theta)  S(m_B) \\[10pt]
&amp;= \int d\hat{z} \int d\hat{m_B} \int dz \int dm_B \, \delta(\hat{z}-z) \mathcal{N}(\hat{m_B}|m_B,\hat{\sigma_{m_B}}) P(m_B|z,\theta) P(z|\theta)  S(m_B) \\[10pt]
&amp;= \int dz \int dm_B \, \left[ \int d\hat{m_B} \mathcal{N}(\hat{m_B}|m_B,\hat{\sigma_{m_B}}) \right] P(m_B|z,\theta) P(z|\theta) S(m_B) \\[10pt]
&amp;= \int dz \left[ \int dm_B \,  S(m_B) P(m_B|z,\theta) \right] P(z|\theta) \\[10pt]\end{split}\]</div>
</div></blockquote>
</div>
<p>As such, we have our efficiency function</p>
<div class="math">
\[\begin{split}S(m_B) = \mathcal{N}_{\rm skew} (m_B | m_{B,{\rm eff}}, \sigma_{{\rm eff}}, \alpha_{\rm eff})\\\end{split}\]</div>
<p>With our survey efficiency thus defined, we need to describe our supernova model as a population
in apparent magnitude (and redshift). This will be given by a normal function with mean
<span class="math">\(m_B^*(z) = \langle M_B \rangle + \mu(z) - \alpha \langle x_1 \rangle + \beta \langle c \rangle\)</span>.
The width of this normal is then given by
<span class="math">\((\sigma_{m_B}^*)^2 = \sigma_{m_B}^2 + (\alpha \sigma_{x_1})^2 + (\beta \sigma_c)^2 + 2(\beta \sigma_{m_B,c} -\alpha \sigma_{m_B,x_1} - \alpha\beta\sigma_{x_1,c})\)</span>,
such that we formally have</p>
<div class="math">
\[\begin{split}P(m_B | z,\theta) &amp;= \mathcal{N}(m_B | m_B^*(z), \sigma_{m_B}^*) \\\end{split}\]</div>
<p>From this, we can derive an approximate weight <span class="math">\(w_{\rm approx}\)</span>:</p>
<div class="math">
\[\begin{split}w_{\rm approx} &amp;= 2 \int dz \,
\mathcal{N} \left( \frac{ m_{B,{\rm eff}} - m_B^*(z) }{ \sqrt{ \sigma_{{\rm eff}}^2 + \sigma_{m_B}^{*2} }} \right)
\Phi\left( \frac{ {\rm sign}(\alpha) \left( m_B^*(z) - m_{B,{\rm eff}} \right) }{ \frac{\sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2}{\sigma_{{\rm eff}}^2} \sqrt{ \left( \frac{ \sigma_{{\rm eff}} }{ \alpha_{\rm eff} }  \right)^2 +      \frac{  \sigma_{m_B}^{*2} \sigma_{{\rm eff}}^2  }{ \sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2 }        } }  \right)
P(z|\theta) \\[10pt]\end{split}\]</div>
<div class="toggle note math admonition">
<p class="first admonition-title">Show/Hide derivation</p>
<blockquote class="last">
<div><div class="math">
\[\begin{split}w_{\rm approx} &amp;= \int dz \left[ \int dm_B \,  S(m_B) P(m_B|z,\theta) \right] P(z|\theta) \\[10pt]
&amp;= \int dz \left[
\int dm_B \,  \mathcal{N}_{\rm skew} (m_B | m_{B,{\rm eff}}, \sigma_{{\rm eff}}, \alpha_{\rm eff})
\mathcal{N}(m_B | m_B^*(z), \sigma_{m_B}^*)
\right] P(z|\theta) \\[10pt]
&amp;= 2 \int dz \left[
\int dm_B \,  \mathcal{N} \left(\frac{m_B - m_{B,{\rm eff}}}{\sigma_{{\rm eff}}}\right) \Phi\left(\alpha_{\rm eff} \frac{m_B - m_{B,{\rm eff}}}{\sigma_{{\rm eff}}}\right)
\mathcal{N}\left(\frac{m_B - m_B^*(z)}{\sigma_{m_B}^*}\right)
\right] P(z|\theta) \\[10pt]
&amp;= 2 \int dz \left[ \int dm_B \,
\mathcal{N} \left( \frac{ m_{B,{\rm eff}} - m_B^*(z) }{ \sqrt{ \sigma_{{\rm eff}}^2 + \sigma_{m_B}^{*2} }} \right)
\mathcal{N} \left( \frac{ m_B - \bar{m_B} }{  \bar{\sigma}_{m_B}  }\right)
\Phi\left(\alpha_{\rm eff} \frac{m_B - m_{B,{\rm eff}}}{\sigma_{{\rm eff}}}\right)
\right] P(z|\theta) \\[10pt]
&amp; {\rm where }\ \  \bar{m_B} = \left( m_{B,{\rm eff}} \sigma_{m_B}^{*2} +   m_B^*(z) \sigma_{{\rm eff}}^2 \right) / \left( \sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2 \right)  \\[10pt]
&amp; {\rm where }\ \  \bar{\sigma}_{m_B}^2 = \left(  \sigma_{m_B}^{*2} \sigma_{{\rm eff}}^2  \right) / \left( \sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2 \right)   \\[10pt]
&amp;= 2 \int dz \,
\mathcal{N} \left( \frac{ m_{B,{\rm eff}} - m_B^*(z) }{ \sqrt{ \sigma_{{\rm eff}}^2 + \sigma_{m_B}^{*2} }} \right)
\left[ \int dm_B \,
\mathcal{N} \left( \frac{ m_B - \bar{m_B} }{  \bar{\sigma}_{m_B}  }\right)
\Phi\left(\alpha_{\rm eff} \frac{m_B - m_{B,{\rm eff}}}{\sigma_{{\rm eff}}}\right)
\right] P(z|\theta) \\[10pt]
&amp;= 2 \int dz \,
\mathcal{N} \left( \frac{ m_{B,{\rm eff}} - m_B^*(z) }{ \sqrt{ \sigma_{{\rm eff}}^2 + \sigma_{m_B}^{*2} }} \right)
\Phi\left( \frac{{\rm sign}(\alpha) \left( \bar{m_B} - m_{B,{\rm eff}} \right)}{ \sqrt{ \left( \frac{ \sigma_{{\rm eff}} }{ \alpha_{\rm eff} }  \right)^2 + \bar{\sigma}_{m_B}^2 } }  \right)
P(z|\theta) \\[10pt]
&amp;= 2 \int dz \,
\mathcal{N} \left( \frac{ m_{B,{\rm eff}} - m_B^*(z) }{ \sqrt{ \sigma_{{\rm eff}}^2 + \sigma_{m_B}^{*2} }} \right)
\Phi\left( \frac{ {\rm sign}(\alpha) \left(  m_B^*(z) - m_{B,{\rm eff}} \right) }{ \frac{\sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2}{\sigma_{{\rm eff}}^2} \sqrt{ \left( \frac{ \sigma_{{\rm eff}} }{ \alpha_{\rm eff} }  \right)^2 +      \frac{  \sigma_{m_B}^{*2} \sigma_{{\rm eff}}^2  }{ \sigma_{m_B}^{*2} +  \sigma_{{\rm eff}}^2 }        } }  \right)
P(z|\theta) \\[10pt]\end{split}\]</div>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Error_function#Integral_of_error_function_with_Gaussian_density_function">Thank you Wikipedia for laying out the second last line out so nicely</a>.</p>
</div></blockquote>
</div>
<p>We can see here that as our skew normal approaches a normal (<span class="math">\(\alpha \rightarrow 0\)</span>), the CDF function tends to
<span class="math">\(\frac{1}{2}\)</span> and gives us only the expected normal residual.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>If we wanted to use the original complimentary CDF approximation for the selection efficiency, we would get the integral
of the complimentary CDF function.</p>
<div class="math">
\[\begin{split}w_{\rm approx} &amp;= 2 \int dz \,
\Phi^c\left( \frac{m_B^* - m_{B,{\rm eff}}}{\sqrt{ {\sigma_{m_B}^*}^2 + \sigma_{{\rm eff}}^2}} \right)
P(z|\theta) \\[10pt]\end{split}\]</div>
<p>Now here we depart from Rubin (2015). Rubin (2015) formulate their likelihood in terms of a combinatorial
problem, taking into account the number of observed events and an unknown number of missed events. Detailed in
their Appendix B, they also make &#8220;the counterintuitive approximation that the redshift of each missed
SN is exactly equal to the redshift of a detected SN. This approximation is accurate because the SN samples have,
on average, enough SNe that the redshift distribution is reasonable sampled.&#8221;</p>
<p>Unfortunately, I must disagree that this approximation is valid, because
whilst the SN surveys <em>may</em> be able to reasonable sample the <em>observed</em> redshift distribution of SN, they
<em>do not</em> adequately sample the underlying redshift distribution, which is important in my formulation.</p>
<p>Now, the underlying redshift distribution goes to a very high redshift,
however we note that we would not have to integrate over all of it, because
above the observed redshift distribution the contribution to the integral quickly drops to zero. However,
sampling the high redshift tail is still necessary.</p>
<p>It is of interest that the difference in methodology (between my integral and Rubin&#8217;s
combinatorics/redshift approximation/geometric series) leads to the following difference in bias corrections.</p>
<p>Note that I use capital W below, to denote a correction for the entire model, not a single supernova.</p>
<div class="math">
\[\begin{split}W_{\rm approx} &amp;= 2 \left(\int dz \,
\Phi^c\left( \frac{m_B^* - m_{B,{\rm eff}}}{\sqrt{ {\sigma_{m_B}^*}^2 +   \sigma_{{\rm survey}}^2}} \right)
P(z|\theta) \right)^N \\[10pt]
W_{\rm Rubin} &amp;= \prod_{i=1}^N \frac{P({\rm detect}|\lbrace \hat{m_{Bi}}, \hat{x_{1i}}, \hat{c_i} \rbrace) }{P({\rm detect} | z_i) }
= \prod_{i=1}^N (\epsilon + P({\rm detect} | z_i))^{-1} \\\end{split}\]</div>
<p>where the last line utilises a small <span class="math">\(\epsilon\)</span> to aid convergences, and we discard the
numerator as Rubin states with <span class="math">\(\epsilon &gt; 0\)</span> it didn&#8217;t turn out to be important.</p>
<p class="last">To try and compare these different methods, I&#8217;ve also tried a similar exact redshift approximation
to reduce my integral down to a product, however it does not work well.</p>
</div>
<p>After fitting the above posterior surface, we can remove the approximation correction
and implement the actual Monte Carlo correction by assigning each point the chain the weight based on the
difference between the approximate weight and the actual weight.</p>
</div>
<div class="section" id="final-model">
<h2>Final Model<a class="headerlink" href="#final-model" title="Permalink to this headline">¶</a></h2>
<p>From the mathematics laid out before, I test three models.</p>
<p>For the first model, as the hostmass distribution and redshift
distribution are not well known, I keep mass and redshift as top level model parameters.
With this, I adopt the assumption of the redshift distribution being well sampled, and apply only the
approximate correction. As such, this will allow me to get a reference for the other two models.</p>
<p>The second and third models have mass and redshift coming from a parent population. The two models
are when applying the full Monte-Carlo correction and when not (keeping it only the approximate 
correction).</p>
<p>To test the models, I have multiple datasets I test them on. The <cite>simple</cite> dataset is one constructed
by hand with simple draws and a perfect selection effect. The SNANA datasets use SNANA and thus
have proper selection effects which are not perfectly skew normal. There are multiple realisations
of <span class="math">\(\Omega_m\)</span>, and a simulation which introduces a skewed colour distribution (bifurcated gaussian 
population).</p>
<div class="figure align-center" id="id8">
<a class="reference internal image-reference" href="../dessn/configurations/plots/approximate_simple_test.png"><img alt="../dessn/configurations/plots/approximate_simple_test.png" src="../dessn/configurations/plots/approximate_simple_test.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Approx simple test, looks good.</span></p>
</div>
<div class="figure align-center" id="id9">
<a class="reference internal image-reference" href="../dessn/configurations/plots/full_simple_test.png"><img alt="../dessn/configurations/plots/full_simple_test.png" src="../dessn/configurations/plots/full_simple_test.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Full simple test, concerns over <span class="math">\(\Omega_m\)</span> when applying the full correction.</span></p>
</div>
<div class="figure align-center" id="id10">
<a class="reference internal image-reference" href="../dessn/configurations/plots/approximate_snana_array_test.png"><img alt="../dessn/configurations/plots/approximate_snana_array_test.png" src="../dessn/configurations/plots/approximate_snana_array_test.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Approximate SNANA tests. Looks good. The underestimation of <span class="math">\(\sigma\)</span> is from SNANA adding
extra uncertainty, and the outlier <span class="math">\(\sigma_c\)</span> from the skewed test is because the bifurcated
gaussian has width 0.1 and 0.05, so 0.75 is the correct value for that dataset.</span></p>
</div>
<div class="figure align-center" id="id11">
<a class="reference internal image-reference" href="../dessn/configurations/plots/full_snana_array_test.png"><img alt="../dessn/configurations/plots/full_snana_array_test.png" src="../dessn/configurations/plots/full_snana_array_test.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-text">Full SNANA tests. Looks good, as above.</span></p>
</div>
<hr class="docutils" />
<div class="line-block">
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
<div class="line"><br /></div>
</div>
</div>
<div class="section" id="appendix-1-mc-inside-stan">
<h2>Appendix 1 - MC inside Stan<a class="headerlink" href="#appendix-1-mc-inside-stan" title="Permalink to this headline">¶</a></h2>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>Given the concerns with the importance sampling methods, I also decided to implement
the bias corrections within STAN itself - that is, have Stan perform rough Monte-Carlo
integration to get the bias correction in explicitly. Inserting the relevant data and structures
into STAN such that I can perform Monte Carlo integration in a BHM framework significantly
slows down the fits, however I believed it would at least give good results.</p>
<p class="last">In addition to the odd contours, we I also see in the walk itself that we have
sampling issues, with some walkers sampling some areas of posterior space more than others.
Stan&#8217;s lack of convergence here is a big issue, indicating that the surfaces adding MC integration
creates are intractable to Stan.</p>
</div>
</div>
<div class="section" id="appendix-2-gaussian-processes">
<h2>Appendix 2 - Gaussian Processes<a class="headerlink" href="#appendix-2-gaussian-processes" title="Permalink to this headline">¶</a></h2>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">As performing Monte Carlo integration inside Stan hit a dead end, I decided to investigate
if I could achieve an approximate solution by using Gaussian Processes. Unfortunately,
what we can see happneing in the plots below is that a single point of in the GP has a substantially
higher weight than the others (a presumed combination of stochastic randomness
and being in an unusual area of parameter space). However, this meant that any walker
randomly initialised near this point would be stuck to it. Even if this did not happen,
viewing the other walkers revealed issues with them preferring matter densities as high as
possible, which is obviously not what is wanted. It seems that without a huge number of points
(which Stan cannot do) our model is too high-dimensional that we cannot use a Gaussian Process.</p>
</div>
</div>
<div class="section" id="appendix-2-nearest-point-gp">
<h2>Appendix 2 - Nearest Point GP<a class="headerlink" href="#appendix-2-nearest-point-gp" title="Permalink to this headline">¶</a></h2>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p>Building off a regular Gaussian Process, the high dimensionality of our model
may be causing difficulties due to the GP kernel - if we are averaging or blending
over too many points (too great a volume in parameter space), we would not expect
accurate results. To test if this was the issue, I increased the number of points
in the GP to a high value (in the thousands), and then modified the distance metric
used to calculate the kernel - raising it to a power and then normalising, such
that the distance to the closest point approached one, and the distance to all
other points approached infinity (or really a number much larger than one).</p>
<p>By doing this - instead of fitting the GP hyper parameters - I have essentially
created a smooth, infinitely-differentiable nearest-point-interpolator. But, looking at
the results below, apparently that is exactly what I don&#8217;t want!</p>
<p class="last">Whats is actually happening is that Stan uses a Hamiltonian Monte Carlo algorithm, which
takes into account the gradient of the posterior surface. The nearest-point GP setup I
am using has extreme gradients because the GP values quickly shift when you cross the equidistant
threshold between two points. These extreme gradients, and the convoluted and chaotic boundaries
given by the equidistant constraint on a thousand points in high dimensional volume, completely
breaks Stan&#8217;s HMC algorithm.</p>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-dessn.framework.models.approx_model">
<span id="dessn-framework-models-approx-model-module"></span><h2>dessn.framework.models.approx_model module<a class="headerlink" href="#module-dessn.framework.models.approx_model" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="dessn.framework.models.approx_model.ApproximateModel">
<em class="property">class </em><code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">ApproximateModel</code><span class="sig-paren">(</span><em>filename='approximate.stan'</em>, <em>num_nodes=4</em>, <em>statonly=False</em>, <em>frac_shift=0.0</em>, <em>apply_efficiency=True</em>, <em>prior=False</em>, <em>lock_systematics=False</em>, <em>lock_disp=False</em>, <em>lock_pop=False</em>, <em>lock_base=False</em>, <em>lock_drift=False</em>, <em>fakes=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="dessn.framework.html#dessn.framework.model.Model" title="dessn.framework.model.Model"><code class="xref py py-class docutils literal"><span class="pre">dessn.framework.model.Model</span></code></a></p>
<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.correct_chain">
<code class="descname">correct_chain</code><span class="sig-paren">(</span><em>dictionary</em>, <em>simulation</em>, <em>data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.correct_chain"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.correct_chain" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_cosmo_params">
<code class="descname">get_cosmo_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_cosmo_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_cosmo_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_data">
<code class="descname">get_data</code><span class="sig-paren">(</span><em>simulations</em>, <em>cosmology_index</em>, <em>add_zs=None</em>, <em>plot=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_data"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_data" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_global_from_sims">
<code class="descname">get_global_from_sims</code><span class="sig-paren">(</span><em>simulations</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_global_from_sims"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_global_from_sims" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_init">
<code class="descname">get_init</code><span class="sig-paren">(</span><em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_init"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_init" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_labels">
<code class="descname">get_labels</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_name">
<code class="descname">get_name</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_name"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_name" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_node_weights">
<code class="descname">get_node_weights</code><span class="sig-paren">(</span><em>nodes</em>, <em>redshifts</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_node_weights"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_node_weights" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_parameters">
<code class="descname">get_parameters</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_parameters" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModel.get_systematic_labels">
<code class="descname">get_systematic_labels</code><span class="sig-paren">(</span><em>simulations</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModel.get_systematic_labels"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModel.get_systematic_labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="dessn.framework.models.approx_model.ApproximateModelOl">
<em class="property">class </em><code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">ApproximateModelOl</code><span class="sig-paren">(</span><em>filename='approximate_ol.stan'</em>, <em>num_nodes=4</em>, <em>statonly=False</em>, <em>frac_shift=1.0</em>, <em>apply_efficiency=True</em>, <em>prior=False</em>, <em>lock_systematics=False</em>, <em>lock_disp=False</em>, <em>lock_pop=False</em>, <em>lock_base=False</em>, <em>lock_drift=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelOl"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelOl" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dessn.framework.models.approx_model.ApproximateModel" title="dessn.framework.models.approx_model.ApproximateModel"><code class="xref py py-class docutils literal"><span class="pre">dessn.framework.models.approx_model.ApproximateModel</span></code></a></p>
<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModelOl.get_cosmo_params">
<code class="descname">get_cosmo_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelOl.get_cosmo_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelOl.get_cosmo_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="dessn.framework.models.approx_model.ApproximateModelW">
<em class="property">class </em><code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">ApproximateModelW</code><span class="sig-paren">(</span><em>filename='approximate_w.stan'</em>, <em>num_nodes=4</em>, <em>statonly=False</em>, <em>prior=False</em>, <em>frac_shift=1.0</em>, <em>apply_efficiency=True</em>, <em>lock_systematics=False</em>, <em>lock_disp=False</em>, <em>lock_pop=False</em>, <em>lock_base=False</em>, <em>lock_drift=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelW"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelW" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dessn.framework.models.approx_model.ApproximateModel" title="dessn.framework.models.approx_model.ApproximateModel"><code class="xref py py-class docutils literal"><span class="pre">dessn.framework.models.approx_model.ApproximateModel</span></code></a></p>
<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModelW.get_cosmo_params">
<code class="descname">get_cosmo_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelW.get_cosmo_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelW.get_cosmo_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="dessn.framework.models.approx_model.ApproximateModelWSimplified">
<em class="property">class </em><code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">ApproximateModelWSimplified</code><span class="sig-paren">(</span><em>filename='approximate_w_simplified.stan'</em>, <em>num_nodes=4</em>, <em>statonly=False</em>, <em>prior=False</em>, <em>frac_shift=1.0</em>, <em>apply_efficiency=True</em>, <em>lock_systematics=False</em>, <em>lock_disp=False</em>, <em>lock_pop=False</em>, <em>lock_drift=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelWSimplified"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelWSimplified" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dessn.framework.models.approx_model.ApproximateModel" title="dessn.framework.models.approx_model.ApproximateModel"><code class="xref py py-class docutils literal"><span class="pre">dessn.framework.models.approx_model.ApproximateModel</span></code></a></p>
<dl class="method">
<dt id="dessn.framework.models.approx_model.ApproximateModelWSimplified.get_cosmo_params">
<code class="descname">get_cosmo_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#ApproximateModelWSimplified.get_cosmo_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.ApproximateModelWSimplified.get_cosmo_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="dessn.framework.models.approx_model.FakeModel">
<em class="property">class </em><code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">FakeModel</code><span class="sig-paren">(</span><em>filename='fake.stan'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#FakeModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.FakeModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#dessn.framework.models.approx_model.ApproximateModel" title="dessn.framework.models.approx_model.ApproximateModel"><code class="xref py py-class docutils literal"><span class="pre">dessn.framework.models.approx_model.ApproximateModel</span></code></a></p>
<dl class="method">
<dt id="dessn.framework.models.approx_model.FakeModel.get_cosmo_params">
<code class="descname">get_cosmo_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/approx_model.html#FakeModel.get_cosmo_params"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.approx_model.FakeModel.get_cosmo_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="function">
<dt id="dessn.framework.models.approx_model.normal">
<code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">normal</code><span class="sig-paren">(</span><em>loc=0.0</em>, <em>scale=1.0</em>, <em>size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dessn.framework.models.approx_model.normal" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw random samples from a normal (Gaussian) distribution.</p>
<p>The probability density function of the normal distribution, first
derived by De Moivre and 200 years later by both Gauss and Laplace
independently <a class="reference internal" href="#r4516de1a6f02-2" id="id3">[2]</a>, is often called the bell curve because of
its characteristic shape (see the example below).</p>
<p>The normal distributions occurs often in nature.  For example, it
describes the commonly occurring distribution of samples influenced
by a large number of tiny, random disturbances, each with its own
unique distribution <a class="reference internal" href="#r4516de1a6f02-2" id="id4">[2]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>loc</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or array_like of floats</span></dt>
<dd><p class="first last">Mean (&#8220;centre&#8221;) of the distribution.</p>
</dd>
<dt><strong>scale</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or array_like of floats</span></dt>
<dd><p class="first last">Standard deviation (spread or &#8220;width&#8221;) of the distribution.</p>
</dd>
<dt><strong>size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int or tuple of ints, optional</span></dt>
<dd><p class="first last">Output shape.  If the given shape is, e.g., <code class="docutils literal"><span class="pre">(m,</span> <span class="pre">n,</span> <span class="pre">k)</span></code>, then
<code class="docutils literal"><span class="pre">m</span> <span class="pre">*</span> <span class="pre">n</span> <span class="pre">*</span> <span class="pre">k</span></code> samples are drawn.  If size is <code class="docutils literal"><span class="pre">None</span></code> (default),
a single value is returned if <code class="docutils literal"><span class="pre">loc</span></code> and <code class="docutils literal"><span class="pre">scale</span></code> are both scalars.
Otherwise, <code class="docutils literal"><span class="pre">np.broadcast(loc,</span> <span class="pre">scale).size</span></code> samples are drawn.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or scalar</span></dt>
<dd><p class="first last">Drawn samples from the parameterized normal distribution.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><code class="xref py py-obj docutils literal"><span class="pre">scipy.stats.norm</span></code></dt>
<dd>probability density function, distribution or cumulative density function, etc.</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The probability density for the Gaussian distribution is</p>
<div class="math">
\[p(x) = \frac{1}{\sqrt{ 2 \pi \sigma^2 }}
e^{ - \frac{ (x - \mu)^2 } {2 \sigma^2} },\]</div>
<p>where <span class="math">\(\mu\)</span> is the mean and <span class="math">\(\sigma\)</span> the standard
deviation. The square of the standard deviation, <span class="math">\(\sigma^2\)</span>,
is called the variance.</p>
<p>The function has its peak at the mean, and its &#8220;spread&#8221; increases with
the standard deviation (the function reaches 0.607 times its maximum at
<span class="math">\(x + \sigma\)</span> and <span class="math">\(x - \sigma\)</span> <a class="reference internal" href="#r4516de1a6f02-2" id="id5">[2]</a>).  This implies that
<cite>numpy.random.normal</cite> is more likely to return samples lying close to
the mean, rather than those far away.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r4516de1a6f02-1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[1]</a></td><td>Wikipedia, &#8220;Normal distribution&#8221;,
<a class="reference external" href="http://en.wikipedia.org/wiki/Normal_distribution">http://en.wikipedia.org/wiki/Normal_distribution</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4516de1a6f02-2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><em>(<a class="fn-backref" href="#id3">1</a>, <a class="fn-backref" href="#id4">2</a>, <a class="fn-backref" href="#id5">3</a>, <a class="fn-backref" href="#id7">4</a>)</em> P. R. Peebles Jr., &#8220;Central Limit Theorem&#8221; in &#8220;Probability,
Random Variables and Random Signal Principles&#8221;, 4th ed., 2001,
pp. 51, 51, 125.</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Draw samples from the distribution:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span> <span class="c1"># mean and standard deviation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>Verify the mean and the variance:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">abs</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">s</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
<span class="go">True</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">abs</span><span class="p">(</span><span class="n">sigma</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span> <span class="o">&lt;</span> <span class="mf">0.01</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Display the histogram of the samples, along with
the probability density function:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">sigma</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">))</span> <span class="o">*</span>
<span class="gp">... </span>               <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span> <span class="o">-</span> <span class="p">(</span><span class="n">bins</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="p">),</span>
<span class="gp">... </span>         <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="dessn.framework.models.approx_model.uniform">
<code class="descclassname">dessn.framework.models.approx_model.</code><code class="descname">uniform</code><span class="sig-paren">(</span><em>low=0.0</em>, <em>high=1.0</em>, <em>size=None</em><span class="sig-paren">)</span><a class="headerlink" href="#dessn.framework.models.approx_model.uniform" title="Permalink to this definition">¶</a></dt>
<dd><p>Draw samples from a uniform distribution.</p>
<p>Samples are uniformly distributed over the half-open interval
<code class="docutils literal"><span class="pre">[low,</span> <span class="pre">high)</span></code> (includes low, but excludes high).  In other words,
any value within the given interval is equally likely to be drawn
by <cite>uniform</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>low</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or array_like of floats, optional</span></dt>
<dd><p class="first last">Lower boundary of the output interval.  All values generated will be
greater than or equal to low.  The default value is 0.</p>
</dd>
<dt><strong>high</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or array_like of floats</span></dt>
<dd><p class="first last">Upper boundary of the output interval.  All values generated will be
less than high.  The default value is 1.0.</p>
</dd>
<dt><strong>size</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int or tuple of ints, optional</span></dt>
<dd><p class="first last">Output shape.  If the given shape is, e.g., <code class="docutils literal"><span class="pre">(m,</span> <span class="pre">n,</span> <span class="pre">k)</span></code>, then
<code class="docutils literal"><span class="pre">m</span> <span class="pre">*</span> <span class="pre">n</span> <span class="pre">*</span> <span class="pre">k</span></code> samples are drawn.  If size is <code class="docutils literal"><span class="pre">None</span></code> (default),
a single value is returned if <code class="docutils literal"><span class="pre">low</span></code> and <code class="docutils literal"><span class="pre">high</span></code> are both scalars.
Otherwise, <code class="docutils literal"><span class="pre">np.broadcast(low,</span> <span class="pre">high).size</span></code> samples are drawn.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>out</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ndarray or scalar</span></dt>
<dd><p class="first last">Drawn samples from the parameterized uniform distribution.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><code class="xref py py-obj docutils literal"><span class="pre">randint</span></code></dt>
<dd>Discrete uniform distribution, yielding integers.</dd>
<dt><code class="xref py py-obj docutils literal"><span class="pre">random_integers</span></code></dt>
<dd>Discrete uniform distribution over the closed interval <code class="docutils literal"><span class="pre">[low,</span> <span class="pre">high]</span></code>.</dd>
<dt><code class="xref py py-obj docutils literal"><span class="pre">random_sample</span></code></dt>
<dd>Floats uniformly distributed over <code class="docutils literal"><span class="pre">[0,</span> <span class="pre">1)</span></code>.</dd>
<dt><code class="xref py py-obj docutils literal"><span class="pre">random</span></code></dt>
<dd>Alias for <cite>random_sample</cite>.</dd>
<dt><code class="xref py py-obj docutils literal"><span class="pre">rand</span></code></dt>
<dd>Convenience function that accepts dimensions as input, e.g., <code class="docutils literal"><span class="pre">rand(2,2)</span></code> would generate a 2-by-2 array of floats, uniformly distributed over <code class="docutils literal"><span class="pre">[0,</span> <span class="pre">1)</span></code>.</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The probability density function of the uniform distribution is</p>
<div class="math">
\[p(x) = \frac{1}{b - a}\]</div>
<p>anywhere within the interval <code class="docutils literal"><span class="pre">[a,</span> <span class="pre">b)</span></code>, and zero elsewhere.</p>
<p>When <code class="docutils literal"><span class="pre">high</span></code> == <code class="docutils literal"><span class="pre">low</span></code>, values of <code class="docutils literal"><span class="pre">low</span></code> will be returned.
If <code class="docutils literal"><span class="pre">high</span></code> &lt; <code class="docutils literal"><span class="pre">low</span></code>, the results are officially undefined
and may eventually raise an error, i.e. do not rely on this
function to behave when passed arguments satisfying that
inequality condition.</p>
<p class="rubric">Examples</p>
<p>Draw samples from the distribution:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
</pre></div>
</div>
<p>All values are within the given interval:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">s</span> <span class="o">&gt;=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="go">True</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">s</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
<p>Display the histogram of the samples, along with the
probability density function:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">count</span><span class="p">,</span> <span class="n">bins</span><span class="p">,</span> <span class="n">ignored</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">bins</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="dessn-framework-models-full-model-module">
<h2>dessn.framework.models.full_model module<a class="headerlink" href="#dessn-framework-models-full-model-module" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-dessn.framework.models.skewness_fix">
<span id="dessn-framework-models-skewness-fix-module"></span><h2>dessn.framework.models.skewness_fix module<a class="headerlink" href="#module-dessn.framework.models.skewness_fix" title="Permalink to this headline">¶</a></h2>
<p>Created on Fri Dec 29 20:44:13 2017</p>
<p>&#64;author: shint1</p>
<dl class="function">
<dt id="dessn.framework.models.skewness_fix.get_approx_efficiency">
<code class="descclassname">dessn.framework.models.skewness_fix.</code><code class="descname">get_approx_efficiency</code><span class="sig-paren">(</span><em>dist_mod</em>, <em>alpha</em>, <em>vals</em>, <em>correction_skewnorm</em>, <em>alpha_shift</em>, <em>frac_shift</em>, <em>frac_shift2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/skewness_fix.html#get_approx_efficiency"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.skewness_fix.get_approx_efficiency" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="dessn.framework.models.skewness_fix.get_selection_cdf">
<code class="descclassname">dessn.framework.models.skewness_fix.</code><code class="descname">get_selection_cdf</code><span class="sig-paren">(</span><em>mbs</em>, <em>vals</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/skewness_fix.html#get_selection_cdf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.skewness_fix.get_selection_cdf" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="dessn.framework.models.skewness_fix.get_selection_skewnorm">
<code class="descclassname">dessn.framework.models.skewness_fix.</code><code class="descname">get_selection_skewnorm</code><span class="sig-paren">(</span><em>mbs</em>, <em>vals</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/skewness_fix.html#get_selection_skewnorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.skewness_fix.get_selection_skewnorm" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="dessn.framework.models.skewness_fix.get_shift_scale">
<code class="descclassname">dessn.framework.models.skewness_fix.</code><code class="descname">get_shift_scale</code><span class="sig-paren">(</span><em>redshifts</em>, <em>correction_skewnorm</em>, <em>vals</em>, <em>frac_shift</em>, <em>frac_shift2</em>, <em>plot=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/dessn/framework/models/skewness_fix.html#get_shift_scale"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#dessn.framework.models.skewness_fix.get_shift_scale" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, dessn.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'0.0.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      <script type="text/javascript" src="_static/mathconf.js"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .admonition-title").show();
        $(".toggle .admonition-title").click(function() {
            $(this).parent().children().not(".admonition-title").toggle(200);
            $(this).parent().toggleClass("open");
            $(this).parent().children(".admonition-title").toggleClass("open");
        })
    });
</script>


</body>
</html>